#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sounddevice as sd
import numpy as np
import wave
from faster_whisper import WhisperModel
import threading, os, time, textwrap
from PIL import Image, ImageDraw, ImageFont
import requests
from collections import deque

# ===== C·∫•u h√¨nh √¢m thanh =====
RECORD_RATE = 44100  # Sample rate c·ªßa thi·∫øt b·ªã
WHISPER_RATE = 16000  # Whisper y√™u c·∫ßu 16kHz
CHANNELS = 1  # USB PnP Sound Device: 1 in (Mono)
DEVICE = 3  # Device 3: USB PnP Sound Device
CHUNK_DURATION = 3.0  # Ghi 3 gi√¢y ‚Üí transcribe ‚Üí l·∫∑p l·∫°i

# ===== LCD =====
FB1 = "/dev/fb1"
W, H = 480, 320
FONT_PATH = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
FONT_SIZE = 22

# ===== Kh·ªüi t·∫°o m√¥ h√¨nh =====
model = WhisperModel("/home/pi/PhoWhisper-tiny-ct2", device="cpu", compute_type="int8")

# ===== L·ªãch s·ª≠ =====
HISTORY_FILE = "history.txt"
SERVER_URL = "http://192.168.10.117:5000/upload_speech"  # Unified server endpoint
MAX_HISTORY = 3
history = []
history_lock = threading.Lock()

# ===== Tr·∫°ng th√°i =====
is_running = False
processing = False

# ===== H√†m ghi framebuffer =====
def write_to_fb(img):
    if img.size != (W, H):
        img = img.resize((W, H))
    arr = np.array(img)
    r = (arr[:, :, 0] >> 3).astype(np.uint16)
    g = (arr[:, :, 1] >> 2).astype(np.uint16)
    b = (arr[:, :, 2] >> 3).astype(np.uint16)
    rgb565 = (r << 11) | (g << 5) | b
    with open(FB1, "wb") as f:
        rgb565.tofile(f)

# ===== Hi·ªÉn th·ªã l·ªãch s·ª≠ =====
def show_recent_history(history, status=""):
    img = Image.new("RGB", (W, H), "white")
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype(FONT_PATH, FONT_SIZE)
    
    # Status
    if status:
        status_font = ImageFont.truetype(FONT_PATH, 18)
        bbox = draw.textbbox((0, 0), status, font=status_font)
        w = bbox[2] - bbox[0]
        draw.text(((W - w) // 2, 10), status, font=status_font, fill="blue")
        y = 50
    else:
        y = 10
    
    # History
    with history_lock:
        for line in history:
            wrapped = textwrap.fill(line, width=25)
            for subline in wrapped.split("\n"):
                bbox = draw.textbbox((0, 0), subline, font=font)
                w = bbox[2] - bbox[0]
                h = bbox[3] - bbox[1]
                x = (W - w) // 2
                draw.text((x, y), subline, font=font, fill="black")
                y += h + 4
            y += 8
    
    write_to_fb(img)

# ===== Resample audio t·ª´ 44100Hz ‚Üí 16000Hz =====
def resample_audio(audio_data, orig_rate, target_rate):
    """Resample ƒë∆°n gi·∫£n b·∫±ng linear interpolation"""
    # Convert stereo to mono n·∫øu c·∫ßn
    if len(audio_data.shape) > 1 and audio_data.shape[1] == 2:
        audio_data = np.mean(audio_data, axis=1).astype(np.int16)
    else:
        audio_data = audio_data.flatten()
    
    if orig_rate == target_rate:
        return audio_data
    
    duration = len(audio_data) / orig_rate
    target_samples = int(duration * target_rate)
    
    # Linear interpolation
    indices = np.linspace(0, len(audio_data) - 1, target_samples)
    resampled = np.interp(indices, np.arange(len(audio_data)), audio_data)
    
    return resampled.astype(np.int16)

# ===== L∆∞u WAV =====
def save_wav(audio_data, filename):
    # Resample xu·ªëng 16kHz cho Whisper (s·∫Ω t·ª± convert stereo‚Üímono)
    resampled = resample_audio(audio_data, RECORD_RATE, WHISPER_RATE)
    
    with wave.open(filename, "wb") as wf:
        wf.setnchannels(1)  # Whisper c·∫ßn mono
        wf.setsampwidth(2)
        wf.setframerate(WHISPER_RATE)
        wf.writeframes(resampled.tobytes())

# ===== G·ª≠i file l√™n server =====
def send_to_server(file_path):
    try:
        with open(file_path, "rb") as f:
            files = {"file": f}
            r = requests.post(SERVER_URL, files=files, timeout=5)
        print(f"üì§ Server: {r.status_code}")
    except Exception as e:
        print(f"‚ùå Server error: {e}")

# ===== X·ª≠ l√Ω transcription =====
def process_audio(audio_data):
    global history, processing
    
    processing = True
    wav_file = "speech_temp.wav"
    save_wav(audio_data, wav_file)
    
    print("üîÑ Transcribing...")
    show_recent_history(history, " ƒêang x·ª≠ l√Ω...")
    
    try:
        segments, _ = model.transcribe(wav_file, beam_size=1, language="vi")
        full_text = " ".join([s.text for s in segments]).strip()
        
        if full_text:
            print(f"‚úÖ K·∫øt qu·∫£: {full_text}")
            
            with history_lock:
                history.append(full_text)
                if len(history) > MAX_HISTORY:
                    history.pop(0)
            
            show_recent_history(history)
            
            # Ghi file
            with open(HISTORY_FILE, "a", encoding="utf-8") as f:
                f.write(full_text + "\n")
            
            # G·ª≠i server
            threading.Thread(target=send_to_server, args=(HISTORY_FILE,), daemon=True).start()
        else:
            print("‚ö†Ô∏è  Kh√¥ng ph√°t hi·ªán gi·ªçng n√≥i")
            show_recent_history(history, "üéß ƒêang nghe...")
            
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        show_recent_history(history, "‚ö†Ô∏è  L·ªói x·ª≠ l√Ω")
    
    finally:
        if os.path.exists(wav_file):
            os.remove(wav_file)
        processing = False

# ===== V√≤ng l·∫∑p ghi √¢m li√™n t·ª•c =====
def continuous_recording():
    global is_running
    
    frames_per_chunk = int(RECORD_RATE * CHUNK_DURATION)
    
    with sd.InputStream(samplerate=RECORD_RATE, channels=CHANNELS, dtype="int16", device=DEVICE) as stream:
        print(f"‚úÖ B·∫Øt ƒë·∫ßu ghi √¢m (m·ªói {CHUNK_DURATION}s)...\n")
        show_recent_history(history, "üéß ƒêang nghe...")
        
        while is_running:
            # Ghi audio trong CHUNK_DURATION gi√¢y
            audio_data, _ = stream.read(frames_per_chunk)
            
            # Ch·ªù x·ª≠ l√Ω xong (n·∫øu ƒëang x·ª≠ l√Ω)
            while processing and is_running:
                time.sleep(0.1)
            
            if not is_running:
                break
            
            # X·ª≠ l√Ω trong thread ri√™ng
            threading.Thread(
                target=process_audio, 
                args=(audio_data.copy(),),
                daemon=True
            ).start()

# ===== Main =====
if __name__ == "__main__":
    print("=" * 60)
    print("üéôÔ∏è  REAL-TIME WHISPER - Fixed-length (Nh·∫π nh·∫•t)")
    print("=" * 60)
    print(f"Ghi m·ªói {CHUNK_DURATION}s ‚Üí transcribe ‚Üí l·∫∑p l·∫°i")
    print(f"Ghi √¢m: {RECORD_RATE} Hz ‚Üí Resample: {WHISPER_RATE} Hz")
    print(f"Device: Card {DEVICE} (USB PnP Sound Device)")
    print("=" * 60)
    print("\nNh·∫•n Enter ƒë·ªÉ b·∫Øt ƒë·∫ßu...")
    print("Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng\n")
    
    input()
    
    is_running = True
    
    try:
        continuous_recording()
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  ƒêang d·ª´ng...")
        is_running = False
        time.sleep(0.5)
        show_recent_history(history, "‚èπÔ∏è  ƒê√£ d·ª´ng")
        print("T·∫°m bi·ªát! üëã")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        is_running = False
